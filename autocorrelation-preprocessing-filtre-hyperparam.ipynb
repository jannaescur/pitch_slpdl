{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F4.wav', 'M3.wav', 'F2.wav', 'F3.wav', 'M2.wav', 'F1.wav', 'M4.wav', 'M5.wav', 'F5.wav', 'M1.wav']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "from types import SimpleNamespace\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import correlate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/test\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def autocorr_method(frame, sfreq, threshold=0.56, fmin=50, fmax=350):\n",
    "    \"\"\"Estimate pitch using autocorrelation\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Calculate autocorrelation using scipy correlate\n",
    "    frame = frame.astype(np.float)\n",
    "    frame -= frame.mean()\n",
    "    amax = np.abs(frame).max()\n",
    "    if amax > 0:\n",
    "        frame /= amax\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    corr = correlate(frame, frame)\n",
    "    # keep the positive part\n",
    "    corr = corr[len(corr)//2:]\n",
    "\n",
    "    # Find the first minimum\n",
    "    dcorr = np.diff(corr)\n",
    "    rmin = np.where(dcorr > 0)[0]\n",
    "    if len(rmin) > 0:\n",
    "        rmin1 = rmin[0]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    # Find the next peak\n",
    "    peak = np.argmax(corr[rmin1:]) + rmin1\n",
    "    rmax = corr[peak]/corr[0]\n",
    "    f0 = sfreq / peak\n",
    "\n",
    "    if rmax > threshold and f0 >= fmin and f0 <= fmax:\n",
    "        return f0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "0c7be69d4071f45f46430daf4015fa8c1145d4da"
   },
   "outputs": [],
   "source": [
    "class Counters:\n",
    "    def __init__(self, gross_threshold=0.2):\n",
    "        self.num_voiced = 0\n",
    "        self.num_unvoiced = 0\n",
    "        self.num_voiced_unvoiced = 0\n",
    "        self.num_unvoiced_voiced = 0\n",
    "        self.num_voiced_voiced = 0\n",
    "        self.num_gross_errors = 0\n",
    "        self.fine_error = 0\n",
    "        self.e2 = 0\n",
    "        self.gross_threshold = gross_threshold\n",
    "        self.nfiles = 0\n",
    "\n",
    "    def add(self, other):\n",
    "        if other is not None:\n",
    "            self.num_voiced += other.num_voiced\n",
    "            self.num_unvoiced += other.num_unvoiced\n",
    "            self.num_voiced_unvoiced += other.num_voiced_unvoiced\n",
    "            self.num_unvoiced_voiced += other.num_unvoiced_voiced\n",
    "            self.num_voiced_voiced += other.num_voiced_voiced\n",
    "            self.num_gross_errors += other.num_gross_errors\n",
    "            self.fine_error += other.fine_error\n",
    "            self.e2 += other.e2\n",
    "            self.nfiles += 1\n",
    "\n",
    "    def __repr__(self):\n",
    "        nframes = self.num_voiced + self.num_unvoiced\n",
    "        if self.nfiles > 0:\n",
    "            self.fine_error /= self.nfiles\n",
    "        str = [\n",
    "            f\"Num. frames:\\t{self.num_unvoiced + self.num_voiced} = {self.num_unvoiced} unvoiced + {self.num_voiced} voiced\",\n",
    "            f\"Unvoiced frames as voiced:\\t{self.num_unvoiced_voiced}/{self.num_unvoiced} ({100*self.num_unvoiced_voiced/self.num_unvoiced:.2f}%)\",\n",
    "            f\"Voiced frames as unvoiced:\\t{self.num_voiced_unvoiced}/{self.num_voiced} ({100*self.num_voiced_unvoiced/self.num_voiced:.2f}%)\",\n",
    "            f\"Gross voiced errors (>{100*self.gross_threshold}%):\\t{self.num_gross_errors}/{self.num_voiced_voiced} ({100*self.num_gross_errors/self.num_voiced_voiced:.2f}%)\",\n",
    "            f\"MSE of fine errors:\\t{100*self.fine_error:.2f}%\",\n",
    "            f\"RMSE:\\t{np.sqrt(self.e2/nframes):.2f}\"\n",
    "        ]\n",
    "        return '\\n'.join(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "e9870d63a5eb733ef6b98f3305b3c2634608bf3f"
   },
   "outputs": [],
   "source": [
    "def compare(fref, pitch):\n",
    "    vref = np.loadtxt(fref)\n",
    "    vtest = np.array(pitch)\n",
    "\n",
    "    diff_frames = len(vref) - len(vtest)\n",
    "    if abs(diff_frames) > 5:\n",
    "        print(f\"Error: number of frames in ref ({len(vref)}) != number of frames in test ({len(vtest)})\")\n",
    "        return None\n",
    "    elif diff_frames > 0:\n",
    "        vref = np.resize(vref, vtest.shape)\n",
    "    elif diff_frames < 0:\n",
    "        vtest = np.resize(vtest, vref.shape)\n",
    "\n",
    "    counters = Counters()\n",
    "    counters.num_voiced = np.count_nonzero(vref)\n",
    "    counters.num_unvoiced = len(vref) - counters.num_voiced\n",
    "    counters.num_unvoiced_voiced = np.count_nonzero(np.logical_and(vref == 0, vtest != 0))\n",
    "    counters.num_voiced_unvoiced = np.count_nonzero(np.logical_and(vref != 0, vtest == 0))\n",
    "\n",
    "    voiced_voiced = np.logical_and(vref != 0, vtest != 0)\n",
    "    counters.num_voiced_voiced = np.count_nonzero(voiced_voiced)\n",
    "\n",
    "    f = np.absolute(vref[voiced_voiced] - vtest[voiced_voiced])/vref[voiced_voiced]\n",
    "    gross_errors = f > counters.gross_threshold\n",
    "    counters.num_gross_errors = np.count_nonzero(gross_errors)\n",
    "    fine_errors = np.logical_not(gross_errors)\n",
    "    counters.fine_error = np.sqrt(np.square(f[fine_errors]).mean())\n",
    "    counters.e2 = np.square(vref - vtest).sum()\n",
    "\n",
    "    return counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "37f3e70917faeb9e5f47d1d53b910ce07bc944a3"
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter, freqz, medfilt, hilbert\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def butter_highpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_highpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def wav2f0(options, gui):\n",
    "    fs = open(options.submission, 'w') if options.submission is not None else None\n",
    "    totalCounters = Counters()\n",
    "    with open(gui) as f:\n",
    "        if fs is not None:\n",
    "            print('id,frequency', file=fs)\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "            filename = os.path.join(options.datadir, line + \".wav\")\n",
    "            f0ref_filename = os.path.join(options.datadir, line + \".f0ref\")\n",
    "            print(\"Processing:\", filename)\n",
    "            sfreq, data = wavfile.read(filename)\n",
    "            nsamples = len(data)\n",
    "            #plt.figure(figsize=(20,10))\n",
    "            #plt.specgram(data, Fs=sfreq, NFFT=1024, noverlap=192, cmap='nipy_spectral', xextent=(0,len(data)))\n",
    "            #plt.ylabel('Frequency [Hz]')\n",
    "            #plt.xlabel('Time [sec]')\n",
    "            #plt.show()\n",
    "\n",
    "            # From miliseconds to samples\n",
    "            ns_windowlength = int(round((options.windowlength * sfreq) / 1000))\n",
    "            ns_frameshift = int(round((options.frameshift * sfreq) / 1000))\n",
    "            ns_left_padding = int(round((options.left_padding * sfreq) / 1000))\n",
    "            ns_right_padding = int(round((options.right_padding * sfreq) / 1000))\n",
    "            pitch = []\n",
    "            \n",
    "            #Pre-processing\n",
    "            cutoff_freq = 300\n",
    "            n_coeficients = 10\n",
    "            \n",
    "            \n",
    "            print(len(data))\n",
    "            \n",
    "            # Get the filter coefficients so we can check its frequency response.\n",
    "            b, a = butter_lowpass(cutoff_freq, sfreq, n_coeficients)\n",
    "            '''\n",
    "            # Plot the frequency response.\n",
    "            w, h = freqz(b, a, worN=8000)\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plt.plot(0.5*sfreq*w/np.pi, np.abs(h), 'b')\n",
    "            plt.plot(cutoff_freq, 0.5*np.sqrt(2), 'ko')\n",
    "            plt.axvline(cutoff_freq, color='k')\n",
    "            plt.xlim(0, 0.5*sfreq)\n",
    "            plt.title(\"Lowpass Filter Frequency Response\")\n",
    "            plt.xlabel('Frequency [Hz]')\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "            break\n",
    "            '''\n",
    "            # Filter the signal\n",
    "            data = butter_lowpass_filter(data, cutoff_freq, sfreq, n_coeficients)\n",
    "            \n",
    "            \n",
    "            cutoff_freq = 50\n",
    "            n_coeficients = 7\n",
    "            '''\n",
    "            b, a = butter_highpass(cutoff_freq, sfreq, n_coeficients)\n",
    "            w, h = freqz(b, a, worN=8000)\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plt.plot(0.5*sfreq*w/np.pi, np.abs(h), 'b')\n",
    "            plt.plot(cutoff_freq, 0.5*np.sqrt(2), 'ko')\n",
    "            plt.axvline(cutoff_freq, color='k')\n",
    "            plt.xlim(0, 200)\n",
    "            plt.title(\"Highpass Filter Frequency Response\")\n",
    "            plt.xlabel('Frequency [Hz]')\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "            break\n",
    "            '''\n",
    "            \n",
    "            \n",
    "            data = butter_highpass_filter(data, cutoff_freq, sfreq, n_coeficients)\n",
    "            \n",
    "            # Preprocessing (centre-clipping)\n",
    "            centreclip = 200\n",
    "            data = (abs(data) > centreclip).astype(np.int) * data\n",
    "            \n",
    "            #print(len(data))\n",
    "            for id, ini in enumerate(range(-ns_left_padding, nsamples - ns_windowlength + ns_right_padding + 1, ns_frameshift)):\n",
    "                first_sample = max(0, ini)\n",
    "                last_sample = min(nsamples, ini + ns_windowlength)\n",
    "                frame = data[first_sample:last_sample]\n",
    "                f0 = autocorr_method(frame, sfreq)\n",
    "                if fs is not None:\n",
    "                    print(line + '_' + str(id) + ',', f0, file=fs)\n",
    "                pitch.append(f0)\n",
    "            # Post-processing\n",
    "            medianwindow = 3\n",
    "            pitch = medfilt(pitch,medianwindow)\n",
    "            if os.path.isfile(f0ref_filename):\n",
    "                counters = compare(f0ref_filename, pitch)\n",
    "                totalCounters.add(counters)\n",
    "\n",
    "    if totalCounters.num_voiced + totalCounters.num_unvoiced > 0:\n",
    "        print(\"### Summary\")\n",
    "        print(totalCounters)\n",
    "        print(\"-------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f611c950eeb79b40456612db424113d5837ac9ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ../input/fda_ue/rl001.wav\n",
      "30000\n",
      "Processing: ../input/fda_ue/rl002.wav\n",
      "40000\n",
      "Processing: ../input/fda_ue/rl003.wav\n",
      "40000\n",
      "Processing: ../input/fda_ue/rl004.wav\n",
      "32000\n",
      "Processing: ../input/fda_ue/rl005.wav\n",
      "30000\n",
      "Processing: ../input/fda_ue/rl006.wav\n",
      "40000\n",
      "Processing: ../input/fda_ue/rl007.wav\n",
      "30000\n",
      "Processing: ../input/fda_ue/rl008.wav\n",
      "40000\n",
      "Processing: ../input/fda_ue/rl009.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/scipy/signal/signaltools.py:491: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return x[reverse].conj()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000\n",
      "Processing: ../input/fda_ue/rl010.wav\n",
      "50000\n",
      "Processing: ../input/fda_ue/rl011.wav\n",
      "40000\n",
      "Processing: ../input/fda_ue/rl012.wav\n",
      "34000\n",
      "Processing: ../input/fda_ue/rl013.wav\n",
      "34000\n",
      "Processing: ../input/fda_ue/rl014.wav\n",
      "30000\n",
      "Processing: ../input/fda_ue/rl015.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/rl016.wav\n",
      "42000\n",
      "Processing: ../input/fda_ue/rl017.wav\n",
      "30000\n",
      "Processing: ../input/fda_ue/rl018.wav\n",
      "24000\n",
      "Processing: ../input/fda_ue/rl019.wav\n",
      "30000\n",
      "Processing: ../input/fda_ue/rl020.wav\n",
      "24000\n",
      "Processing: ../input/fda_ue/rl021.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/rl022.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/rl023.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/rl024.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/rl025.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/rl026.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/rl027.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/rl028.wav\n",
      "100000\n",
      "Processing: ../input/fda_ue/rl029.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/rl030.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl031.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/rl032.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl033.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl034.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl035.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/rl036.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl037.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl038.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl039.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl040.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl041.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl042.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl043.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl044.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl045.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl046.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl047.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl048.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl049.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/rl050.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb001.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb002.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb003.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb004.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb005.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb006.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb007.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb008.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb009.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb010.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb011.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb012.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb013.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb014.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb015.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb016.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb017.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb018.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb019.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb020.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb021.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb022.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb023.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb024.wav\n",
      "60000\n",
      "Processing: ../input/fda_ue/sb025.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb026.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb027.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb028.wav\n",
      "100000\n",
      "Processing: ../input/fda_ue/sb029.wav\n",
      "100000\n",
      "Processing: ../input/fda_ue/sb030.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb031.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb032.wav\n",
      "100000\n",
      "Processing: ../input/fda_ue/sb033.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb034.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb035.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb036.wav\n",
      "100000\n",
      "Processing: ../input/fda_ue/sb037.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb038.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb039.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb040.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb041.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb042.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb043.wav\n",
      "100000\n",
      "Processing: ../input/fda_ue/sb044.wav\n",
      "100000\n",
      "Processing: ../input/fda_ue/sb045.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb046.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb047.wav\n",
      "120000\n",
      "Processing: ../input/fda_ue/sb048.wav\n",
      "80000\n",
      "Processing: ../input/fda_ue/sb049.wav\n",
      "100000\n",
      "Processing: ../input/fda_ue/sb050.wav\n",
      "80000\n",
      "### Summary\n",
      "Num. frames:\t22140 = 13916 unvoiced + 8224 voiced\n",
      "Unvoiced frames as voiced:\t364/13916 (2.62%)\n",
      "Voiced frames as unvoiced:\t745/8224 (9.06%)\n",
      "Gross voiced errors (>20.0%):\t55/7479 (0.74%)\n",
      "MSE of fine errors:\t2.81%\n",
      "RMSE:\t38.94\n",
      "-------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fda_ue_options = SimpleNamespace(\n",
    "    windowlength=32, frameshift=15, left_padding=16, right_padding=16, datadir='../input', submission=None)\n",
    "wav2f0(fda_ue_options, '../input/fda_ue.gui')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "74599d24c27013ae1a90007812b76e9dc576a903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ../input/test/F1.wav\n",
      "644201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/scipy/signal/signaltools.py:491: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return x[reverse].conj()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ../input/test/F2.wav\n",
      "674001\n",
      "Processing: ../input/test/F3.wav\n",
      "610001\n",
      "Processing: ../input/test/F4.wav\n",
      "632001\n",
      "Processing: ../input/test/F5.wav\n",
      "774001\n",
      "Processing: ../input/test/M1.wav\n",
      "747501\n",
      "Processing: ../input/test/M2.wav\n",
      "637501\n",
      "Processing: ../input/test/M3.wav\n",
      "543501\n",
      "Processing: ../input/test/M4.wav\n",
      "674001\n",
      "Processing: ../input/test/M5.wav\n",
      "806001\n"
     ]
    }
   ],
   "source": [
    "test_options = SimpleNamespace(\n",
    "    windowlength=26.5, frameshift=10, left_padding=13.25, right_padding=7, datadir='../input/test', submission='submission.csv')\n",
    "wav2f0(test_options, '../input/test.gui')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
